# -*- coding: utf-8 -*-
"""deep_learning_diabetes_pytorch.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1oXmK3lQRTMSgiIXA-GgsPYzxgN-hY3y6

#Base de dados retidado do kaggle

https://www.kaggle.com/uciml/pima-indians-diabetes-database

O codigo a seguir foi construito somente para demonstração de conhecimento sem nehum uso profissional.

The following code was created only to demonstrate knowledge without professional use.

El siguiente código fue creado solo para demostrar conocimiento sin uso profesional.
"""

import pandas as pd
from sklearn.model_selection import train_test_split
from torch.utils.tensorboard import SummaryWriter
import numpy as np
import seaborn as sns
from sklearn.metrics import confusion_matrix, accuracy_score
import matplotlib.pyplot as plt

import torch
torch.__version__

import torch.nn as nn

"""#Base de dados
https://www.sharpsightlabs.com/blog/numpy-random-seed/
"""

np.random.seed(123)
torch.manual_seed(123)

data = pd.read_csv('diabetes.csv')

data.head()

data.shape

data.isnull().values.any()

data

data.info()

data.describe()

sns.countplot(x = 'Outcome', data = data);

data.hist(figsize=(20,12));

sns.pairplot(data, hue = 'Outcome', 
             vars = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age']);

"""#Mapa Correlação"""

sns.heatmap(data.corr(), annot = True);

"""#Divisão dos dados"""

X = data.iloc[:, 0:8].values

X

y = data.iloc[:, 8].values

y

#https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html

from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
X = sc.fit_transform(X)

X

#https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)

X_train.shape

y_train.shape

X_test.shape

y_test.shape

type(X_train)

X_train = torch.tensor(np.array(X_train), dtype=torch.float)
y_train = torch.tensor(np.array(y_train), dtype = torch.float)

X_test = torch.tensor(np.array(X_test), dtype=torch.float)
y_test = torch.tensor(np.array(y_test), dtype = torch.float)

X_train

y_train

"""https://pytorch.org/tutorials/beginner/data_loading_tutorial.html"""

dataset = torch.utils.data.TensorDataset(X_train, y_train)

type(dataset)

train_loader = torch.utils.data.DataLoader(dataset, batch_size=30, shuffle=True)

"""https://pytorch.org/docs/master/nn.html

https://pytorch.org/docs/master/generated/torch.nn.Sequential.html#torch.nn.Sequential

https://pytorch.org/docs/master/generated/torch.nn.Dropout.html
"""

classifier = nn.Sequential(
    nn.Linear(in_features=8, out_features=8, bias=True),
    nn.Tanh(),
    nn.Dropout(0.3),
    nn.Linear(8, 8, bias=True),
    nn.Tanh(),
    nn.Dropout(0.3),
    nn.Linear(8,1, bias=True),
    nn.Sigmoid()
)

classifier.parameters

criterion = nn.BCELoss()

"""https://pytorch.org/docs/stable/optim.html"""

optimizer = torch.optim.Adagrad(classifier.parameters(), lr=0.01, weight_decay=0.0001)

"""https://pytorch.org/docs/stable/generated/torch.eq.html"""

train_acc = []
train_loss = []
total_step = len(train_loader)
correct = 0
total=0
for epoch in range(1000):
  running_loss = 0.
  
  for data in train_loader:
  
    inputs, labels = data
    #print(inputs)
    #print('-----')
    #print(labels)
    optimizer.zero_grad()
    
    outputs = classifier(inputs) # classifier.forward(inputs)
    #print(outputs)
    loss = criterion(outputs, labels)
    #print(loss)
    loss.backward()
    optimizer.step()

    running_loss += loss.item()
    

  acc = torch.eq(outputs.round(), labels).float().mean() # accuracy

  _,predicted = torch.max(outputs, dim=1)
  correct += torch.sum(predicted==labels).item()
  total += labels.size(0)
  
  print('epoch %3d: loss %.5f: Accuracy: %.5f' % (epoch+1, running_loss/len(train_loader), acc))

  
  #print(correct)
  #print(total)

  train_acc.append(100 * correct / total)
  train_loss.append(running_loss/total_step)

classifier.eval()

plt.title("Train - Validation Loss")
  plt.plot( train_loss, label='train');

plt.title("Train - Validation Accuracy")
plt.plot(train_acc, label='train');

prev = classifier.forward(X_test)

prev

prevision = np.array(prev > 0.5)
prevision

accuracy = accuracy_score(y_test, prevision)
accuracy

from sklearn.metrics import confusion_matrix
y_train_pred = classifier.forward(X_train)
y_train_pred = (y_train_pred > 0.5)
cm = confusion_matrix(y_train, y_train_pred)
sns.heatmap(cm, annot=True);

cm

from sklearn.metrics import classification_report
print(classification_report(y_train_pred, y_train))

cm = confusion_matrix(y_test, prevision)
sns.heatmap(cm, annot=True);

from sklearn.metrics import classification_report
print(classification_report(y_test, prevision))